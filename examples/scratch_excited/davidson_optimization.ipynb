{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "# === IMPORTS ===\n",
    "\n",
    "import logging, sys\n",
    "import torch\n",
    "import seqm\n",
    "from ase.io import read as ase_read\n",
    "from seqm.seqm_functions.constants import Constants\n",
    "from seqm.Molecule import Molecule\n",
    "from seqm.ElectronicStructure import Electronic_Structure\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "from seqm.seqm_functions.fock import fock\n",
    "from seqm.seqm_functions.pack import unpack\n",
    "import seqm.seqm_functions.pack as pack\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#=== TORCH OPTIONS ===\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "dtype = torch.float64\n",
    "# torch.set_printoptions(precision=5, linewidth=200, profile=\"full\", sci_mode=False)\n",
    "torch.set_printoptions(precision=5, linewidth=200, sci_mode=False, profile = 'short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.functional.norm(input, p: Union[float, str, NoneType] = 'fro', dim=None, keepdim=False, out=None, dtype=None)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colored logging with custom level QM for deeper routines\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(funcName)s : %(lineno)d : %(levelname)s : %(message)s')\n",
    "\n",
    "QM1 = evel=logging.DEBUG - 3 # informal level of depth; QM1 - almost always, usually outside of loops\n",
    "QM2 = evel=logging.DEBUG - 4 #                          QM2 - sometimes, in the loops\n",
    "QM3 = evel=logging.DEBUG - 5\n",
    "\n",
    "logging.addLevelName(QM1, \"QM1\")\n",
    "def qm1(self, message, *args, **kwargs):\n",
    "    if self.isEnabledFor(QM1 ):\n",
    "        self._log(QM1, message, args, **kwargs) \n",
    "        \n",
    "logging.addLevelName(QM2, \"QM2\")\n",
    "def qm2(self, message, *args, **kwargs):\n",
    "    if self.isEnabledFor(QM2):\n",
    "        self._log(QM2, message, args, **kwargs) \n",
    " \n",
    "logging.addLevelName(QM3, \"QM3\")\n",
    "def qm3(self, message, *args, **kwargs):\n",
    "    if self.isEnabledFor(QM3 ):\n",
    "        self._log(QM3, message, args, **kwargs) \n",
    "           \n",
    "        \n",
    "logging.Logger.qm1 = qm1   \n",
    "logging.Logger.qm2 = qm2\n",
    "logging.Logger.qm3 = qm3\n",
    "  \n",
    "logger = logging.getLogger()\n",
    "\n",
    "                              \n",
    "colors = {'qm'        : ('cyan',     None, None),\n",
    "          'matrix'    : ('blue',     None, ['bold']),\n",
    "          'vector'    : ('yellow',   None, ['bold']),\n",
    "          'evals'     : ('green',    None, ['bold']),\n",
    "          'warn'     : ('red',    None, ['bold'])\n",
    "          }\n",
    "\n",
    "def fmt_log(data, message, fmt):\n",
    "    \"\"\"\n",
    "    fmt_log : formats log message with color and style using termcolor module\n",
    "\n",
    "    Args:\n",
    "        data (any): data to print\n",
    "        message (str or None): message to print, pass None if no message is needed\n",
    "        fmt (str): style from colors dict\n",
    "\n",
    "    Returns:\n",
    "        str: formatted string with color and style\n",
    "    \"\"\"    \n",
    "\n",
    "    if type(data) is list or type(data) is tuple or type(data) is torch.Tensor:\n",
    "        \n",
    "        mes = f'{colored(message, colors[fmt][0], colors[fmt][1], attrs=colors[fmt][2])}\\n' # add new line to align array\n",
    "    else:\n",
    "        mes = f'{colored(message, colors[fmt][0], colors[fmt][1], attrs=colors[fmt][2])} : '\n",
    "        \n",
    "    if data == None:\n",
    "        return mes\n",
    "    else:\n",
    "        return mes + str(colored(data, colors[fmt][0], colors[fmt][1], attrs=colors[fmt][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log\n",
    "\n",
    "07/13/23 - QM part seems to be wortking fine\n",
    "full diagonalization agrees with NEXMD\n",
    "small guess space misses relevant vectors, but large guess includes them\n",
    "\n",
    "\n",
    "PASCAL 1 COULD BE INCORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_seqm_1mol(xyz):\n",
    "    \"\"\"\n",
    "    run_seqm_1mol : run PYSEQM for a single molecule\n",
    "\n",
    "    Args:\n",
    "        xyz (str): path to xyz file\n",
    "\n",
    "    Returns:\n",
    "        Molecule object: PYSEQM object with molecule data\n",
    "    \"\"\"    \n",
    "    \n",
    "    atoms = ase_read(xyz)\n",
    "    species = torch.tensor([atoms.get_atomic_numbers()], dtype=torch.long, device=device)\n",
    "    coordinates = torch.tensor([atoms.get_positions()], dtype=dtype, device=device)\n",
    "    \n",
    "    const = Constants().to(device)\n",
    "\n",
    "    elements = [0]+sorted(set(species.reshape(-1).tolist()))\n",
    "\n",
    "    seqm_parameters = {\n",
    "                    'method' : 'PM3',  # AM1, MNDO, PM#\n",
    "                    'scf_eps' : 1.0e-6,  # unit eV, change of electric energy, as nuclear energy doesnt' change during SCF\n",
    "                    'scf_converger' : [2,0.0], # converger used for scf loop\n",
    "                                            # [0, 0.1], [0, alpha] constant mixing, P = alpha*P + (1.0-alpha)*Pnew\n",
    "                                            # [1], adaptive mixing\n",
    "                                            # [2], adaptive mixing, then pulay\n",
    "                    'sp2' : [False, 1.0e-5],  # whether to use sp2 algorithm in scf loop,\n",
    "                                                #[True, eps] or [False], eps for SP2 conve criteria\n",
    "                    'elements' : elements, #[0,1,6,8],\n",
    "                    'learned' : [], # learned parameters name list, e.g ['U_ss']\n",
    "                    #'parameter_file_dir' : '../seqm/params/', # file directory for other required parameters\n",
    "                    'pair_outer_cutoff' : 1.0e10, # consistent with the unit on coordinates\n",
    "                    'eig' : True,\n",
    "                    'excited' : True,\n",
    "                    }\n",
    "\n",
    "    mol = seqm.Molecule.Molecule(const, seqm_parameters, coordinates, species).to(device)\n",
    "\n",
    "    ### Create electronic structure driver:\n",
    "    esdriver = Electronic_Structure(seqm_parameters).to(device)\n",
    "\n",
    "    ### Run esdriver on m:\n",
    "    esdriver(mol)\n",
    "    \n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_seqm(xyz_list):\n",
    "    \"\"\"\n",
    "    run_seqm_1mol : run PYSEQM for a single molecule\n",
    "\n",
    "    Args:\n",
    "        xyz (str): path to xyz file\n",
    "\n",
    "    Returns:\n",
    "        Molecule object: PYSEQM object with molecule data\n",
    "    \"\"\"    \n",
    "    \n",
    "    atoms = [ase_read(x) for x in xyz_list]\n",
    "    species = torch.tensor([atoms[x].get_atomic_numbers() for x in range(len(atoms))], dtype=torch.long, device=device)\n",
    "    coordinates = torch.tensor([atoms[x].get_positions() for x in range(len(atoms))], dtype=dtype, device=device)\n",
    "    \n",
    "    const = Constants().to(device)\n",
    "\n",
    "    elements = [0]+sorted(set(species.reshape(-1).tolist()))\n",
    "\n",
    "    seqm_parameters = {\n",
    "                    'method' : 'PM3',  # AM1, MNDO, PM#\n",
    "                    'scf_eps' : 1.0e-6,  # unit eV, change of electric energy, as nuclear energy doesnt' change during SCF\n",
    "                    'scf_converger' : [2,0.0], # converger used for scf loop\n",
    "                                            # [0, 0.1], [0, alpha] constant mixing, P = alpha*P + (1.0-alpha)*Pnew\n",
    "                                            # [1], adaptive mixing\n",
    "                                            # [2], adaptive mixing, then pulay\n",
    "                    'sp2' : [False, 1.0e-5],  # whether to use sp2 algorithm in scf loop,\n",
    "                                                #[True, eps] or [False], eps for SP2 conve criteria\n",
    "                    'elements' : elements, #[0,1,6,8],\n",
    "                    'learned' : [], # learned parameters name list, e.g ['U_ss']\n",
    "                    #'parameter_file_dir' : '../seqm/params/', # file directory for other required parameters\n",
    "                    'pair_outer_cutoff' : 1.0e10, # consistent with the unit on coordinates\n",
    "                    'eig' : True,\n",
    "                    'excited' : True,\n",
    "                    }\n",
    "\n",
    "    mol = seqm.Molecule.Molecule(const, seqm_parameters, coordinates, species).to(device)\n",
    "\n",
    "    ### Create electronic structure driver:\n",
    "    esdriver = Electronic_Structure(seqm_parameters).to(device)\n",
    "\n",
    "    ### Run esdriver on m:\n",
    "    esdriver(mol)\n",
    "    \n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = run_seqm(['h2o.xyz', 'h2o.xyz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecules.nocc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = run_seqm_1mol('h2o.xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Molecule(\n",
       "  (const): Constants()\n",
       "  (parser): Parser()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUX routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAVIDSON routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)  # custom logging level; lower than DEBUG\n",
    "                               # printed above QM (QM, DEBUG, INFO, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFACTORING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqm.seqm_functions.excited.ortho import orthogonalize_matrix as orthogonal\n",
    "from seqm.seqm_functions.excited.hamiltonian import gen_V\n",
    "from seqm.seqm_functions.excited.hamiltonian import form_cis\n",
    "import seqm.seqm_functions.excited\n",
    "from seqm.seqm_functions.excited.orb_transform import mo2ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def davidson(device, mol, N_exc, keep_n, n_V_max,  max_iter, tol):\n",
    "    \"\"\"\n",
    "    Davidson algorithm for solving eigenvalue problem of large sparse diagonally dominant matrices\n",
    "    Hamiltonian is not generated or stored explicitly, only matrix-vector products are used on-the fly:\n",
    "    guess space V should be orthogonalized at each iteration\n",
    "    M (projection of smaller size) is V.T @ H @ V \n",
    "    #! RPA (TDHF) is not implemented yet, non-Hermitian (non-symmetric), requires also left eigenvectors \n",
    "    note that notation differes between implementations: V.T x A x V is bAb\n",
    "    # TODO: 1) check if convergence of e_vals is needed\n",
    "    # TODO: 2) vectorize and optimize orthogonalization\n",
    "    # TODO: 3) check if some vectors should be dropped \n",
    "    # TODO: 4) eliminate loops \n",
    "    # TODO: 5) check if whole M should be regenerated, or only sub-blocks corresponding to new guess vectors\n",
    "    # TODO: 6) add parameter checker like Krylov dims << N_cis\n",
    "\n",
    "    Args:\n",
    "        mol (PYSEQM object): object to hold all qm data from PYSEQM\n",
    "        N_exc (int)        : number of excited states to calculate\n",
    "        keep_n (int)       : number of e_vals, e_vecs to keep at each iteration\n",
    "        n_V_max (int)      : maximum size of Krylov subspace, \n",
    "                             projected matrix will be no more than M(n_V_max x n_V_max)\n",
    "        max_iter (int)     : maximum number of iterations in Davidson\n",
    "        tol (float)        : treshold for residual\n",
    "        \n",
    "    Returns:\n",
    "        tuple of tensors: eigenvalues (excitation energies in default units, eV) and eigenvectors \n",
    "    \"\"\"    \n",
    "    \n",
    "    n_V_start = N_exc * 2 # dimension of Krylov subspace, analogue of nd1  \n",
    "    N_cis = mol.nocc * mol.nvirt\n",
    "    term = False  # terminate algorithm\n",
    "    iter = 0\n",
    "    \n",
    "    V = gen_V(device, mol, N_cis, n_V_start) # generate initial guess, V here #! should be renamed\n",
    "    diag = None # create diagonal of M only once\n",
    "    \n",
    "    while iter < max_iter and not term: # Davidson loop\n",
    "        \n",
    "        if iter > 0: # skip first step, as initial V is orthogonal\n",
    "            V = torch.squeeze(V) #TODO: remove\n",
    "            V = orthogonal(V)\n",
    "            V = torch.unsqueeze(V, 0)\n",
    "        print('=================================', flush=True)\n",
    "        print(colored(f' ITERATION : {iter} ', 'red', 'on_white', attrs=['bold']), flush=True)\n",
    "        print('SUBSPACE SIZE V: ', V.shape, flush=True)\n",
    "        print('=================================')\n",
    "        # ---------- form A x b product --------------------\n",
    "        H_V = torch.zeros((mol.nmol, N_cis, V.shape[2]), device=device) #! formerly L_xi\n",
    "                                                                        # Hamiltonian @ V \n",
    "        #logger.qm1(fmt_log(V, 'V BEFORE L_xi after ORTO', 'qm'))\n",
    "        #L_xi = form_cis(device, V, mol, N_cis, N_rpa)\n",
    "        \n",
    "        for i in range(V.shape[2]): \n",
    "            # print('=================================', flush=True)\n",
    "            logger.qm3('Lxi iterations=%s', i)\n",
    "            H_V[:, :, i] = form_cis(device, V[:, : ,i], mol, N_cis)\n",
    "        H_V = torch.squeeze(H_V)\n",
    "        \n",
    "        print('H_V shape: ', H_V.shape)\n",
    "\n",
    "        # print('H_V\\n', H_V)\n",
    "        # raise ValueError(' ### STOP ###')\n",
    "        # logger.qm1(fmt_log(right_V.shape, 'right_V shape', 'matrix'))\n",
    "        # logger.qm1(fmt_log(right_V, 'right_V', 'matrix'))       \n",
    "        # ---------- form b.T x Ab product --------------------\n",
    "        V = torch.squeeze(V) # TODO: remove squeeze\n",
    "        print('V shape after SQUEZZE: ', V.shape)\n",
    "        M = V.T @ H_V\n",
    "        print('M shape: ', M.shape)\n",
    "        # logger.debug(fmt_log(M.shape, 'M shape', 'qm'))\n",
    "        # logger.debug(fmt_log(M, 'M', 'qm'))\n",
    "        if iter == 0:\n",
    "            diag = torch.diag(M) # create diagonal only once\n",
    "            \n",
    "        iter += 1\n",
    "        \n",
    "        logger.qm1(fmt_log(diag, 'diag', 'qm'))\n",
    "    \n",
    "        # ---------- diagonalize projection M --------------------\n",
    "        r_eval, r_evec = torch.linalg.eigh(M) # find eigenvalues and eigenvectors\n",
    "       \n",
    "        r_eval = r_eval.real\n",
    "        r_evec = r_evec.real\n",
    "        r_eval, r_idx = torch.sort(r_eval, descending=False) # sort eigenvalues in ascending order\n",
    "        logger.debug(fmt_log(r_eval, 'RIGHT EVALS', 'evals'))\n",
    "        r_evec = r_evec[:, r_idx] # sort eigenvectors accordingly\n",
    "    \n",
    "        e_val_n = r_eval[:keep_n] # keep only the lowest keep_n eigenvalues; full are still stored as e_val\n",
    "        e_vec_n = r_evec[:, :keep_n]\n",
    "        resids = torch.zeros(V.shape[0], len(e_val_n)) # account for left and right evecs\n",
    "\n",
    "        # ---------- calculate residual vectors --------------------\n",
    "        for j in range(len(e_val_n)): # calc residuals \n",
    "            resids[:,j] = H_V @ e_vec_n[:,j] - e_val_n[j] * (V @ e_vec_n[:,j])\n",
    "            \n",
    "       # logger.debug(fmt_log(resids, 'resids', 'matrix'))     \n",
    "        resids_norms_r = torch.tensor([resids[:,x].norm() for x in range(resids.shape[1])])\n",
    "\n",
    "        # ---------- expand guess space V buy not-converged resids --------------------\n",
    "        # !!! PROBABLY HIGHLY INEFFICIENT !!! \n",
    "        print('V shape LINE 101: ', V.shape)\n",
    "        if torch.any(resids_norms_r > tol):\n",
    "            mask_r = resids_norms_r >= tol\n",
    "            large_res_r = resids[:,mask_r] # residuals larger than tol\n",
    "           # logger.debug(fmt_log(large_res_r, 'LARGE RESIDUALS', 'vector'))           \n",
    "            large_res_r.to(device)\n",
    "            cor_e_val_r = e_val_n[mask_r] # corresponding eigenvalues !!! check if matches\n",
    "            \n",
    "            # ------keep adding new resids --------------------\n",
    "            if V.shape[1] <= n_V_max:     \n",
    "\n",
    "                    for j in range(large_res_r.shape[1]):\n",
    "                        if V.shape[1] <= n_V_max:\n",
    "                            s = large_res_r[:,j] # conditioned residuals > tol\n",
    "\n",
    "                            if s.norm() >= tol:\n",
    "                                logger.debug(fmt_log((s.norm().item()), 'NORM of RESIDUAL', 'warn'))\n",
    "                                denom = (diag[j] - cor_e_val_r[j])\n",
    "                                denom.to(device) \n",
    "                                s = s/denom # conditioned residuals\n",
    "                                s.to(device)\n",
    "                                # logger.debug(fmt_log(s.norm(), 'NORM OF NEW RESIDUAAL', 'vector'))\n",
    "                                V = torch.column_stack((V, s/s.norm()))\n",
    "                            else:\n",
    "                                pass\n",
    "                #    V = torch.unsqueeze(V, 0) # TODO: remove\n",
    "                    print('V shape after expansion LINE 125: ', V.shape)\n",
    "\n",
    "            # ------ collapse (restart) if space V is too large; mix eigenvectors with V------------\n",
    "            else:\n",
    "                logger.debug(fmt_log(None, '!!!! MAX subspace reached !!!!', 'warn'))\n",
    "                #logger.debug(fmt_log(V, 'V before collapse', 'qm'))\n",
    "\n",
    "                V =  V @ r_evec[:, :n_V_start]\n",
    "              #  V = torch.unsqueeze(V, 0) # TODO: remove\n",
    "                logger.debug(fmt_log(V.shape, 'V shape after restart', 'qm'))\n",
    "                #logger.debug(fmt_log(V, 'V AFTER collapse', 'qm'))\n",
    "\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            term = True\n",
    "            print('============================', flush=True)\n",
    "            print('all residuals are below tolerance')\n",
    "            print('DAVIDSON ALGORITHM CONVERGED', flush=True)\n",
    "            print('============================', flush=True)\n",
    "\n",
    "            return r_eval, r_evec\n",
    "\n",
    "    # runs after big loop if did not converge\n",
    "    print('============================', flush=True)\n",
    "    print('!!! DAVIDSON ALGORITHM DID NOT CONVERGE !!!', flush=True)\n",
    "    print('============================', flush=True)\n",
    "    \n",
    "    return r_eval, r_evec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module> : 13 : DEBUG : \u001b[1m\u001b[32mFINAL eval \u001b[0m\n",
      "\u001b[1m\u001b[32mtensor([ 5.94858,  6.83013,  9.23851,  9.99968, 11.31665, 12.61708], grad_fn=<SortBackward0>)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == GEN V ==\n",
      "V shape torch.Size([1, 8, 6])\n",
      "V\n",
      " tensor([[[0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0.]]])\n",
      "=================================\n",
      "\u001b[1m\u001b[47m\u001b[31m ITERATION : 0 \u001b[0m\n",
      "SUBSPACE SIZE V:  torch.Size([1, 8, 6])\n",
      "=================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "view(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mseqm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseqm_functions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcited\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39morb_transform\u001b[39;00m \u001b[39mimport\u001b[39;00m mo2ao\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m mol \u001b[39m=\u001b[39m run_seqm_1mol(\u001b[39m'\u001b[39m\u001b[39mh2o.xyz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39meval\u001b[39m, _ \u001b[39m=\u001b[39m davidson(device \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                    mol \u001b[39m=\u001b[39;49m mol, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                    N_exc \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                    keep_n \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                    n_V_max \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                    max_iter \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                    tol \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1e-6\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(fmt_log(\u001b[39meval\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFINAL eval \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mevals\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(V\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]): \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m# print('=================================', flush=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     logger\u001b[39m.\u001b[39mqm3(\u001b[39m'\u001b[39m\u001b[39mLxi iterations=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, i)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     H_V[:, :, i] \u001b[39m=\u001b[39m form_cis(device, V[:, : ,i], molecules, N_cis)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mH_V shape: \u001b[39m\u001b[39m'\u001b[39m, H_V\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mH_V\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, H_V)\n",
      "File \u001b[0;32m/auto/nest/nest/u/fns/github/PYSEQM/seqm/seqm_functions/excited/hamiltonian.py:57\u001b[0m, in \u001b[0;36mform_cis\u001b[0;34m(device, V, mol, N_cis, CIS)\u001b[0m\n\u001b[1;32m     54\u001b[0m nHydro \u001b[39m=\u001b[39m mol\u001b[39m.\u001b[39mnHydro\n\u001b[1;32m     56\u001b[0m V_orig \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclone(V)\n\u001b[0;32m---> 57\u001b[0m V_ao \u001b[39m=\u001b[39m  mo2ao(device, N_cis, V, mol)     \u001b[39m# mo to ao basis (mo2site)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mV_ao.shape\u001b[39m\u001b[39m'\u001b[39m, V_ao\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m(V_ao)\n",
      "File \u001b[0;32m/auto/nest/nest/u/fns/github/PYSEQM/seqm/seqm_functions/excited/orb_transform.py:20\u001b[0m, in \u001b[0;36mmo2ao\u001b[0;34m(device, N_cis, V_mo, mol)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmo2ao\u001b[39m(device, N_cis, V_mo, mol):\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m   Transforms the density matrix from MO to AO basis.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m   Vectorized adaptation of subroutine site2ao from Lioville in NEXMD\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m    - V_ao (torch.Tensor): Guess in AO basis of shape (nmol, norb, norb).\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     V_mo \u001b[39m=\u001b[39m V_mo\u001b[39m.\u001b[39;49mview(mol\u001b[39m.\u001b[39;49mnmol, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, mol\u001b[39m.\u001b[39;49mnvirt) \u001b[39m# reshape V[:, :, i], column, to 2d in batch of mols\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     V_mo_tmp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((mol\u001b[39m.\u001b[39mnmol, mol\u001b[39m.\u001b[39mnorb, mol\u001b[39m.\u001b[39mnorb), device\u001b[39m=\u001b[39mdevice) \u001b[39m# temp storage, presumably faster than padding\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     V_ao \u001b[39m=\u001b[39m V_mo \u001b[39m@\u001b[39m mol\u001b[39m.\u001b[39mC_mo[:, :, mol\u001b[39m.\u001b[39mnocc:mol\u001b[39m.\u001b[39mnorb]\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m) \u001b[39m# operations on |X|, |Y| from RPA is ignored for now\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: view(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 3"
     ]
    }
   ],
   "source": [
    "# mol = run_seqm_1mol('c6h6.xyz')\n",
    "# eval, _ = davidson(mol = mol, \n",
    "#                    N_exc = 8,\n",
    "#                    keep_n = 4,\n",
    "#                    n_V_max = 50, \n",
    "#                    max_iter = 50, \n",
    "#                    tol = 1e-6)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "logger.debug(fmt_log(eval, 'FINAL eval ', 'evals'))\n",
    "from seqm.seqm_functions.excited import ortho as orthogonalize\n",
    "from seqm.seqm_functions.excited.hamiltonian import gen_V\n",
    "from seqm.seqm_functions.excited.hamiltonian import form_cis\n",
    "from seqm.seqm_functions.excited.orb_transform import mo2ao\n",
    "\n",
    "\n",
    "\n",
    "mol = run_seqm_1mol('h2o.xyz')\n",
    "eval, _ = davidson(device = 'cpu', \n",
    "                   mol = mol, \n",
    "                   N_exc = 3,\n",
    "                   keep_n = 2,\n",
    "                   n_V_max = 10, \n",
    "                   max_iter = 3, \n",
    "                   tol = -1e-6)\n",
    "\n",
    "logger.debug(fmt_log(eval, 'FINAL eval ', 'evals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module> : 13 : DEBUG : \u001b[1m\u001b[32mFINAL eval \u001b[0m\n",
      "\u001b[1m\u001b[32mtensor([ 5.94858,  6.83013,  9.23851,  9.99968, 11.31665, 12.61708], grad_fn=<SortBackward0>)\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zeros(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mseqm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseqm_functions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcited\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39morb_transform\u001b[39;00m \u001b[39mimport\u001b[39;00m mo2ao\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m mol \u001b[39m=\u001b[39m run_seqm([\u001b[39m'\u001b[39m\u001b[39mh2o.xyz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mh2o.xyz\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39meval\u001b[39m, _ \u001b[39m=\u001b[39m davidson(device \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                    mol \u001b[39m=\u001b[39;49m mol, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                    N_exc \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                    keep_n \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                    n_V_max \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                    max_iter \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                    tol \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1e-6\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(fmt_log(\u001b[39meval\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFINAL eval \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mevals\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m term \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# terminate algorithm\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39miter\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m V \u001b[39m=\u001b[39m gen_V(device, molecules, N_cis, n_V_start) \u001b[39m# generate initial guess, V here #! should be renamed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m diag \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m# create diagonal of M only once\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m<\u001b[39m max_iter \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m term: \u001b[39m# Davidson loop\u001b[39;00m\n",
      "File \u001b[0;32m/auto/nest/nest/u/fns/github/PYSEQM/seqm/seqm_functions/excited/hamiltonian.py:289\u001b[0m, in \u001b[0;36mgen_V\u001b[0;34m(device, mol, N_cis, n_V_start)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_V\u001b[39m(device, mol, N_cis, n_V_start):\n\u001b[1;32m    287\u001b[0m     \n\u001b[1;32m    288\u001b[0m     \u001b[39m# returns V (formerly vexp1) - guess vector for L-xi routine\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     V \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros((mol\u001b[39m.\u001b[39;49mnmol, N_cis, N_cis), device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    292\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(mol\u001b[39m.\u001b[39mnmol):\n\u001b[1;32m    294\u001b[0m       rrwork \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(N_cis \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, device\u001b[39m=\u001b[39mdevice) \u001b[39m# TODO: VECTORIZE\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: zeros(): argument 'size' must be tuple of ints, but found element of type Tensor at pos 2"
     ]
    }
   ],
   "source": [
    "# mol = run_seqm_1mol('c6h6.xyz')\n",
    "# # eval, _ = davidson(mol = mol, \n",
    "# #                    N_exc = 8,\n",
    "# #                    keep_n = 4,\n",
    "# #                    n_V_max = 50, \n",
    "# #                    max_iter = 50, \n",
    "# #                    tol = 1e-6)\n",
    "\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "# logger.debug(fmt_log(eval, 'FINAL eval ', 'evals'))\n",
    "# from seqm.seqm_functions.excited import ortho as orthogonalize\n",
    "# from seqm.seqm_functions.excited.hamiltonian import gen_V\n",
    "# from seqm.seqm_functions.excited.hamiltonian import form_cis\n",
    "# from seqm.seqm_functions.excited.orb_transform import mo2ao\n",
    "\n",
    "\n",
    "\n",
    "# mol = run_seqm(['h2o.xyz', 'h2o.xyz'])\n",
    "# eval, _ = davidson(device = 'cpu', \n",
    "#                    mol = mol, \n",
    "#                    N_exc = 3,\n",
    "#                    keep_n = 2,\n",
    "#                    n_V_max = 10, \n",
    "#                    max_iter = 3, \n",
    "#                    tol = -1e-6)\n",
    "\n",
    "# logger.debug(fmt_log(eval, 'FINAL eval ', 'evals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module> : 13 : DEBUG : \u001b[1m\u001b[32mFINAL eval \u001b[0m\n",
      "\u001b[1m\u001b[32mtensor([ 5.94858,  6.83013,  9.23851,  9.99968, 11.31665, 12.61708], grad_fn=<SortBackward0>)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == GEN V ==\n",
      "V shape torch.Size([1, 8, 6])\n",
      "V\n",
      " tensor([[[0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0.]]])\n",
      "=================================\n",
      "\u001b[1m\u001b[47m\u001b[31m ITERATION : 0 \u001b[0m\n",
      "SUBSPACE SIZE V:  torch.Size([1, 1, 8, 6])\n",
      "=================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 1.  Target sizes: [1, 4, 6].  Tensor sizes: [3, 6]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mseqm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseqm_functions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcited\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39morb_transform\u001b[39;00m \u001b[39mimport\u001b[39;00m mo2ao\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m mol \u001b[39m=\u001b[39m run_seqm_1mol(\u001b[39m'\u001b[39m\u001b[39mh2o.xyz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39meval\u001b[39m, _ \u001b[39m=\u001b[39m davidson(device \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                    mol \u001b[39m=\u001b[39;49m mol, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                    N_exc \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                    keep_n \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                    n_V_max \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                    max_iter \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                    tol \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1e-6\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(fmt_log(\u001b[39meval\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFINAL eval \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mevals\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb Cell 20\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(V\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]): \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m# print('=================================', flush=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     logger\u001b[39m.\u001b[39mqm3(\u001b[39m'\u001b[39m\u001b[39mLxi iterations=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, i)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     H_V[:, :, i] \u001b[39m=\u001b[39m form_cis(device, V[:, : ,i], mol, N_cis)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m H_V \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(H_V)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mH_V shape: \u001b[39m\u001b[39m'\u001b[39m, H_V\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/auto/nest/nest/u/fns/github/PYSEQM/seqm/seqm_functions/excited/hamiltonian.py:57\u001b[0m, in \u001b[0;36mform_cis\u001b[0;34m(device, V, mol, N_cis, CIS)\u001b[0m\n\u001b[1;32m     54\u001b[0m nHydro \u001b[39m=\u001b[39m mol\u001b[39m.\u001b[39mnHydro\n\u001b[1;32m     56\u001b[0m V_orig \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclone(V)\n\u001b[0;32m---> 57\u001b[0m V_ao \u001b[39m=\u001b[39m  mo2ao(device, N_cis, V, mol)     \u001b[39m# mo to ao basis (mo2site)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mV_ao.shape\u001b[39m\u001b[39m'\u001b[39m, V_ao\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m(V_ao)\n",
      "File \u001b[0;32m/auto/nest/nest/u/fns/github/PYSEQM/seqm/seqm_functions/excited/orb_transform.py:24\u001b[0m, in \u001b[0;36mmo2ao\u001b[0;34m(device, N_cis, V_mo, mol)\u001b[0m\n\u001b[1;32m     21\u001b[0m V_mo_tmp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((mol\u001b[39m.\u001b[39mnmol, mol\u001b[39m.\u001b[39mnorb, mol\u001b[39m.\u001b[39mnorb), device\u001b[39m=\u001b[39mdevice) \u001b[39m# temp storage, presumably faster than padding\u001b[39;00m\n\u001b[1;32m     23\u001b[0m V_ao \u001b[39m=\u001b[39m V_mo \u001b[39m@\u001b[39m mol\u001b[39m.\u001b[39mC_mo[:, :, mol\u001b[39m.\u001b[39mnocc:mol\u001b[39m.\u001b[39mnorb]\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m) \u001b[39m# operations on |X|, |Y| from RPA is ignored for now\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m V_mo_tmp[:, :mol\u001b[39m.\u001b[39mnocc] \u001b[39m=\u001b[39m V_ao\n\u001b[1;32m     26\u001b[0m V_ao \u001b[39m=\u001b[39m mol\u001b[39m.\u001b[39mC_mo \u001b[39m@\u001b[39m V_mo_tmp\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m V_ao\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 1.  Target sizes: [1, 4, 6].  Tensor sizes: [3, 6]"
     ]
    }
   ],
   "source": [
    "# mol = run_seqm_1mol('c6h6.xyz')\n",
    "# eval, _ = davidson(mol = mol, \n",
    "#                    N_exc = 8,\n",
    "#                    keep_n = 4,\n",
    "#                    n_V_max = 50, \n",
    "#                    max_iter = 50, \n",
    "#                    tol = 1e-6)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "logger.debug(fmt_log(eval, 'FINAL eval ', 'evals'))\n",
    "from seqm.seqm_functions.excited import ortho as orthogonalize\n",
    "from seqm.seqm_functions.excited.hamiltonian import gen_V\n",
    "from seqm.seqm_functions.excited.hamiltonian import form_cis\n",
    "from seqm.seqm_functions.excited.orb_transform import mo2ao\n",
    "\n",
    "\n",
    "\n",
    "mol = run_seqm_1mol('h2o.xyz')\n",
    "eval, _ = davidson(device = 'cpu', \n",
    "                   mol = mol, \n",
    "                   N_exc = 3,\n",
    "                   keep_n = 2,\n",
    "                   n_V_max = 10, \n",
    "                   max_iter = 3, \n",
    "                   tol = -1e-6)\n",
    "\n",
    "logger.debug(fmt_log(eval, 'FINAL eval ', 'evals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-36.58831, -17.32189, -14.70534, -12.33198,   4.02645,   5.08758,   0.00000,   0.00000,   0.00000,   0.00000,   0.00000,   0.00000]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol.e_mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol.nHeavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " mol.norb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    -0.87887,     -0.00000,     -0.00000,     -0.10818,     -0.32855,     -0.32855],\n",
       "         [    -0.00000,     -0.00000,     -0.77088,      0.00000,     -0.45041,      0.45041],\n",
       "         [     0.34020,     -0.00000,     -0.00000,     -0.82490,     -0.31921,     -0.31921],\n",
       "         [     0.00000,      1.00000,     -0.00000,     -0.00000,     -0.00000,     -0.00000],\n",
       "         [    -0.33445,     -0.00000,     -0.00000,     -0.55482,      0.53866,      0.53866],\n",
       "         [    -0.00000,      0.00000,      0.63698,     -0.00000,     -0.54510,      0.54510]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol.C_mo.transpose(1,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
