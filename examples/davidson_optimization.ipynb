{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Decorating your function! <function KSA_XL_BOMD.one_step at 0x7f07295e1c60>\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "# === IMPORTS ===\n",
    "\n",
    "import logging, sys\n",
    "import torch\n",
    "import seqm\n",
    "from ase.io import read as ase_read\n",
    "from seqm.seqm_functions.constants import Constants\n",
    "from seqm.Molecule import Molecule\n",
    "from seqm.ElectronicStructure import Electronic_Structure\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "from seqm.seqm_functions.fock import fock\n",
    "from seqm.seqm_functions.pack import unpack\n",
    "import seqm.seqm_functions.pack as pack\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#=== TORCH OPTIONS ===\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "dtype = torch.float64\n",
    "# torch.set_printoptions(precision=5, linewidth=200, profile=\"full\", sci_mode=False)\n",
    "torch.set_printoptions(precision=5, linewidth=200, sci_mode=False, profile = 'short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colored logging with custom level QM for deeper routines\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(funcName)s : %(lineno)d : %(levelname)s : %(message)s')\n",
    "\n",
    "QM1 = evel=logging.DEBUG - 3 # informal level of depth; QM1 - almost always, usually outside of loops\n",
    "QM2 = evel=logging.DEBUG - 4 #                          QM2 - sometimes, in the loops\n",
    "QM3 = evel=logging.DEBUG - 5\n",
    "\n",
    "logging.addLevelName(QM1, \"QM1\")\n",
    "def qm1(self, message, *args, **kwargs):\n",
    "    if self.isEnabledFor(QM1 ):\n",
    "        self._log(QM1, message, args, **kwargs) \n",
    "        \n",
    "logging.addLevelName(QM2, \"QM2\")\n",
    "def qm2(self, message, *args, **kwargs):\n",
    "    if self.isEnabledFor(QM2):\n",
    "        self._log(QM2, message, args, **kwargs) \n",
    " \n",
    "logging.addLevelName(QM3, \"QM3\")\n",
    "def qm3(self, message, *args, **kwargs):\n",
    "    if self.isEnabledFor(QM3 ):\n",
    "        self._log(QM3, message, args, **kwargs) \n",
    "           \n",
    "        \n",
    "logging.Logger.qm1 = qm1   \n",
    "logging.Logger.qm2 = qm2\n",
    "logging.Logger.qm3 = qm3\n",
    "  \n",
    "logger = logging.getLogger()\n",
    "\n",
    "                              \n",
    "colors = {'qm'        : ('cyan',     None, None),\n",
    "          'matrix'    : ('blue',     None, ['bold']),\n",
    "          'vector'    : ('yellow',   None, ['bold']),\n",
    "          'evals'     : ('green',    None, ['bold']),\n",
    "          'warn'     : ('red',    None, ['bold'])\n",
    "          }\n",
    "\n",
    "def fmt_log(data, message, fmt):\n",
    "    \"\"\"\n",
    "    fmt_log : formats log message with color and style using termcolor module\n",
    "\n",
    "    Args:\n",
    "        data (any): data to print\n",
    "        message (str or None): message to print, pass None if no message is needed\n",
    "        fmt (str): style from colors dict\n",
    "\n",
    "    Returns:\n",
    "        str: formatted string with color and style\n",
    "    \"\"\"    \n",
    "\n",
    "    if type(data) is list or type(data) is tuple or type(data) is torch.Tensor:\n",
    "        \n",
    "        mes = f'{colored(message, colors[fmt][0], colors[fmt][1], attrs=colors[fmt][2])}\\n' # add new line to align array\n",
    "    else:\n",
    "        mes = f'{colored(message, colors[fmt][0], colors[fmt][1], attrs=colors[fmt][2])} : '\n",
    "        \n",
    "    if data == None:\n",
    "        return mes\n",
    "    else:\n",
    "        return mes + str(colored(data, colors[fmt][0], colors[fmt][1], attrs=colors[fmt][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log\n",
    "\n",
    "07/13/23 - QM part seems to be wortking fine\n",
    "full diagonalization agrees with NEXMD\n",
    "small guess space misses relevant vectors, but large guess includes them\n",
    "\n",
    "\n",
    "PASCAL 1 COULD BE INCORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_seqm_1mol(xyz):\n",
    "    \"\"\"\n",
    "    run_seqm_1mol : run PYSEQM for a single molecule\n",
    "\n",
    "    Args:\n",
    "        xyz (str): path to xyz file\n",
    "\n",
    "    Returns:\n",
    "        Molecule object: PYSEQM object with molecule data\n",
    "    \"\"\"    \n",
    "    \n",
    "    atoms = ase_read(xyz)\n",
    "    species = torch.tensor([atoms.get_atomic_numbers()], dtype=torch.long, device=device)\n",
    "    coordinates = torch.tensor([atoms.get_positions()], dtype=dtype, device=device)\n",
    "    \n",
    "    const = Constants().to(device)\n",
    "\n",
    "    elements = [0]+sorted(set(species.reshape(-1).tolist()))\n",
    "\n",
    "    seqm_parameters = {\n",
    "                    'method' : 'PM3',  # AM1, MNDO, PM#\n",
    "                    'scf_eps' : 1.0e-6,  # unit eV, change of electric energy, as nuclear energy doesnt' change during SCF\n",
    "                    'scf_converger' : [2,0.0], # converger used for scf loop\n",
    "                                            # [0, 0.1], [0, alpha] constant mixing, P = alpha*P + (1.0-alpha)*Pnew\n",
    "                                            # [1], adaptive mixing\n",
    "                                            # [2], adaptive mixing, then pulay\n",
    "                    'sp2' : [False, 1.0e-5],  # whether to use sp2 algorithm in scf loop,\n",
    "                                                #[True, eps] or [False], eps for SP2 conve criteria\n",
    "                    'elements' : elements, #[0,1,6,8],\n",
    "                    'learned' : [], # learned parameters name list, e.g ['U_ss']\n",
    "                    #'parameter_file_dir' : '../seqm/params/', # file directory for other required parameters\n",
    "                    'pair_outer_cutoff' : 1.0e10, # consistent with the unit on coordinates\n",
    "                    'eig' : True,\n",
    "                    'excited' : True,\n",
    "                    }\n",
    "\n",
    "    mol = seqm.Molecule.Molecule(const, seqm_parameters, coordinates, species).to(device)\n",
    "\n",
    "    ### Create electronic structure driver:\n",
    "    esdriver = Electronic_Structure(seqm_parameters).to(device)\n",
    "\n",
    "    ### Run esdriver on m:\n",
    "    esdriver(mol)\n",
    "    \n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_seqm(xyz_list):\n",
    "    \"\"\"\n",
    "    run_seqm_1mol : run PYSEQM for a single molecule\n",
    "\n",
    "    Args:\n",
    "        xyz (str): path to xyz file\n",
    "\n",
    "    Returns:\n",
    "        Molecule object: PYSEQM object with molecule data\n",
    "    \"\"\"    \n",
    "    \n",
    "    atoms = [ase_read(x) for x in xyz_list]\n",
    "    species = torch.tensor([atoms[x].get_atomic_numbers() for x in range(len(atoms))], dtype=torch.long, device=device)\n",
    "    coordinates = torch.tensor([atoms[x].get_positions() for x in range(len(atoms))], dtype=dtype, device=device)\n",
    "    \n",
    "    const = Constants().to(device)\n",
    "\n",
    "    elements = [0]+sorted(set(species.reshape(-1).tolist()))\n",
    "\n",
    "    seqm_parameters = {\n",
    "                    'method' : 'PM3',  # AM1, MNDO, PM#\n",
    "                    'scf_eps' : 1.0e-6,  # unit eV, change of electric energy, as nuclear energy doesnt' change during SCF\n",
    "                    'scf_converger' : [2,0.0], # converger used for scf loop\n",
    "                                            # [0, 0.1], [0, alpha] constant mixing, P = alpha*P + (1.0-alpha)*Pnew\n",
    "                                            # [1], adaptive mixing\n",
    "                                            # [2], adaptive mixing, then pulay\n",
    "                    'sp2' : [False, 1.0e-5],  # whether to use sp2 algorithm in scf loop,\n",
    "                                                #[True, eps] or [False], eps for SP2 conve criteria\n",
    "                    'elements' : elements, #[0,1,6,8],\n",
    "                    'learned' : [], # learned parameters name list, e.g ['U_ss']\n",
    "                    #'parameter_file_dir' : '../seqm/params/', # file directory for other required parameters\n",
    "                    'pair_outer_cutoff' : 1.0e10, # consistent with the unit on coordinates\n",
    "                    'eig' : True,\n",
    "                    'excited' : True,\n",
    "                    }\n",
    "\n",
    "    mol = seqm.Molecule.Molecule(const, seqm_parameters, coordinates, species).to(device)\n",
    "\n",
    "    ### Create electronic structure driver:\n",
    "    esdriver = Electronic_Structure(seqm_parameters).to(device)\n",
    "\n",
    "    ### Run esdriver on m:\n",
    "    esdriver(mol)\n",
    "    \n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_759627/352110633.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1678411187366/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  species = torch.tensor([atoms[x].get_atomic_numbers() for x in range(len(atoms))], dtype=torch.long, device=device)\n"
     ]
    }
   ],
   "source": [
    "molecules = run_seqm(['h2o.xyz', 'h2o.xyz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecules.nocc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = run_seqm_1mol('h2o.xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Molecule(\n",
       "  (const): Constants()\n",
       "  (parser): Parser()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUX routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAVIDSON routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)  # custom logging level; lower than DEBUG\n",
    "                               # printed above QM (QM, DEBUG, INFO, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFACTORING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqm.seqm_functions.excited import ortho as orthogonalize\n",
    "from seqm.seqm_functions.excited.hamiltonian import gen_V\n",
    "from seqm.seqm_functions.excited.hamiltonian import form_cis_nexmd, form_cis\n",
    "import seqm.seqm_functions.excited\n",
    "from seqm.seqm_functions.excited.orb_transform import mo2ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def davidson(device, mol, N_exc, keep_n, n_V_max,  max_iter, tol):\n",
    "    \"\"\"\n",
    "    Davidson algorithm for solving eigenvalue problem of large sparse diagonally dominant matrices\n",
    "    Hamiltonian is not generated or stored explicitly, only matrix-vector products are used on-the fly:\n",
    "    guess space V should be orthogonalized at each iteration\n",
    "    M (projection of smaller size) is V.T @ H @ V \n",
    "    #! RPA (TDHF) is not implemented yet, non-Hermitian (non-symmetric), requires also left eigenvectors \n",
    "    note that notation differes between implementations: V.T x A x V is bAb\n",
    "    # TODO: 1) check if convergence of e_vals is needed\n",
    "    # TODO: 2) vectorize and optimize orthogonalization\n",
    "    # TODO: 3) check if some vectors should be dropped \n",
    "    # TODO: 4) eliminate loops \n",
    "    # TODO: 5) check if whole M should be regenerated, or only sub-blocks corresponding to new guess vectors\n",
    "    # TODO: 6) add parameter checker like Krylov dims << N_cis\n",
    "\n",
    "    Args:\n",
    "        mol (PYSEQM object): object to hold all qm data from PYSEQM\n",
    "        N_exc (int)        : number of excited states to calculate\n",
    "        keep_n (int)       : number of e_vals, e_vecs to keep at each iteration\n",
    "        n_V_max (int)      : maximum size of Krylov subspace, \n",
    "                             projected matrix will be no more than M(n_V_max x n_V_max)\n",
    "        max_iter (int)     : maximum number of iterations in Davidson\n",
    "        tol (float)        : treshold for residual\n",
    "        \n",
    "    Returns:\n",
    "        tuple of tensors: eigenvalues (excitation energies in default units, eV) and eigenvectors \n",
    "    \"\"\"    \n",
    "    \n",
    "    n_V_start = N_exc * 2 # dimension of Krylov subspace, analogue of nd1  \n",
    "    N_cis = mol.nocc * mol.nvirt\n",
    "    N_rpa = 2 * N_cis\n",
    "    \n",
    "    term = False  # terminate algorithm\n",
    "    iter = 0\n",
    "    #L_xi = torch.zeros((N_rpa, n_V_start), device=device)\n",
    "    V = gen_V(device, mol, N_cis, N_rpa, n_V_start) # generate initial guess, V here #! should be renamed\n",
    "    diag = None # create diagonal of M only once\n",
    "    \n",
    "    while iter < max_iter and not term: # Davidson loop\n",
    "        \n",
    "        if iter > 0: # skip first step, as initial V is orthogonal\n",
    "            V = orthogonalize(V)\n",
    "            \n",
    "        print('=================================', flush=True)\n",
    "        print(colored(f' ITERATION : {iter} ', 'red', 'on_white', attrs=['bold']), flush=True)\n",
    "        print('SUBSPACE SIZE V: ', V.shape, flush=True)\n",
    "        print('=================================')\n",
    "       \n",
    "        # ---------- form A x b product --------------------\n",
    "        L_xi = torch.zeros((mol.nmol, N_cis, V.shape[2]), device=device) #! NOT iter here\n",
    "\n",
    "        logger.qm1(fmt_log(V, 'V BEFORE L_xi after ORTO', 'qm'))\n",
    "        \n",
    "        # L_xi = form_cis(device, V, mol, N_cis, N_rpa)\n",
    "        \n",
    "        for i in range(V.shape[2]): \n",
    "            # print('=================================', flush=True)\n",
    "            logger.qm3('Lxi iterations=%s', i)\n",
    "            L_xi[:, :, i] = form_cis_nexmd(device, V[:, : ,i], mol, N_cis)\n",
    "\n",
    "        # raise ValueError('======= STOP ===========')\n",
    "        # logger.qm3(fmt_log(L_xi, 'L_xi', 'qm'))\n",
    "        print('L_xi.shape', L_xi.shape)\n",
    "        print('L_xi\\n', L_xi)\n",
    "        raise ValueError('STOP')\n",
    "        L_xi[N_cis:, :] = L_xi[:N_cis] #! TODO: make sure that this A+B, A-B, not just copy for RPA\n",
    "    \n",
    "        right_V = L_xi[N_cis:] # (A)b \n",
    "        \n",
    "        # logger.qm1(fmt_log(right_V.shape, 'right_V shape', 'matrix'))\n",
    "        # logger.qm1(fmt_log(right_V, 'right_V', 'matrix'))       \n",
    "        # ---------- form b.T x Ab product --------------------\n",
    "        \n",
    "        M =  V.T @ right_V\n",
    "        \n",
    "        # logger.debug(fmt_log(M.shape, 'M shape', 'qm'))\n",
    "        # logger.debug(fmt_log(M, 'M', 'qm'))\n",
    "        if iter == 0:\n",
    "            diag = torch.diag(M) # create diagonal only once\n",
    "            \n",
    "        iter += 1\n",
    "        \n",
    "        logger.qm1(fmt_log(diag, 'diag', 'qm'))\n",
    "    \n",
    "        # ---------- diagonalize projection M --------------------\n",
    "        r_eval, r_evec = torch.linalg.eigh(M) # find eigenvalues and eigenvectors\n",
    "       \n",
    "        r_eval = r_eval.real\n",
    "        r_evec = r_evec.real\n",
    "        r_eval, r_idx = torch.sort(r_eval, descending=False) # sort eigenvalues in ascending order\n",
    "        logger.debug(fmt_log(r_eval, 'RIGHT EVALS', 'evals'))\n",
    "        r_evec = r_evec[:, r_idx] # sort eigenvectors accordingly\n",
    "    \n",
    "        e_val_n = r_eval[:keep_n] # keep only the lowest keep_n eigenvalues; full are still stored as e_val\n",
    "        e_vec_n = r_evec[:, :keep_n]\n",
    "        resids = torch.zeros(V.shape[0], len(e_val_n)) # account for left and right evecs\n",
    "\n",
    "        # ---------- calculate residual vectors --------------------\n",
    "        for j in range(len(e_val_n)): # calc residuals \n",
    "            resids[:,j] = right_V @ e_vec_n[:,j] - e_val_n[j] * (V @ e_vec_n[:,j])\n",
    "            \n",
    "       # logger.debug(fmt_log(resids, 'resids', 'matrix'))     \n",
    "        resids_norms_r = torch.tensor([resids[:,x].norm() for x in range(resids.shape[1])])\n",
    "\n",
    "        # ---------- expand guess space V buy not-converged resids --------------------\n",
    "        # !!! PROBABLY HIGHLY INEFFICIENT !!! \n",
    "        if torch.any(resids_norms_r > tol):\n",
    "            mask_r = resids_norms_r >= tol\n",
    "            large_res_r = resids[:,mask_r] # residuals larger than tol\n",
    "           # logger.debug(fmt_log(large_res_r, 'LARGE RESIDUALS', 'vector'))           \n",
    "            large_res_r.to(device)\n",
    "            cor_e_val_r = e_val_n[mask_r] # corresponding eigenvalues !!! check if matches\n",
    "            \n",
    "            # ------keep adding new resids --------------------\n",
    "            if V.shape[1] <= n_V_max:     \n",
    "\n",
    "                    for j in range(large_res_r.shape[1]):\n",
    "                        if V.shape[1] <= n_V_max:\n",
    "                            s = large_res_r[:,j] # conditioned residuals > tol\n",
    "\n",
    "                            if s.norm() >= tol:\n",
    "                                logger.debug(fmt_log((s.norm().item()), 'NORM of RESIDUAL', 'warn'))\n",
    "                                denom = (diag[j] - cor_e_val_r[j])\n",
    "                                denom.to(device) \n",
    "                                s = s/denom # conditioned residuals\n",
    "                                s.to(device)\n",
    "                                # logger.debug(fmt_log(s.norm(), 'NORM OF NEW RESIDUAAL', 'vector'))\n",
    "                                V = torch.column_stack((V, s/s.norm()))\n",
    "                            else:\n",
    "                                pass\n",
    "            # ------ collapse (restart) if space V is too large; mix eigenvectors with V------------\n",
    "            else:\n",
    "                logger.debug(fmt_log(None, '!!!! MAX subspace reached !!!!', 'warn'))\n",
    "                #logger.debug(fmt_log(V, 'V before collapse', 'qm'))\n",
    "\n",
    "                V =  V @ r_evec[:, :n_V_start]\n",
    "                logger.debug(fmt_log(V.shape, 'V shape after restart', 'qm'))\n",
    "                #logger.debug(fmt_log(V, 'V AFTER collapse', 'qm'))\n",
    "\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            term = True\n",
    "            print('============================', flush=True)\n",
    "            print('all residuals are below tolerance')\n",
    "            print('DAVIDSON ALGORITHM CONVERGED', flush=True)\n",
    "            print('============================', flush=True)\n",
    "\n",
    "            return r_eval, r_evec\n",
    "\n",
    "    # runs after big loop if did not converge\n",
    "    print('============================', flush=True)\n",
    "    print('!!! DAVIDSON ALGORITHM DID NOT CONVERGE !!!', flush=True)\n",
    "    print('============================', flush=True)\n",
    "    \n",
    "    return r_eval, r_evec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<module> : 13 : DEBUG : \u001b[1m\u001b[32mFINAL eval \u001b[0m\n",
      "\u001b[1m\u001b[32mtensor([-10.58943, -10.40985, -10.26553,  -9.94604,  -9.55941,  -9.33964], grad_fn=<SortBackward0>)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " == GEN V ==\n",
      "V shape torch.Size([1, 8, 6])\n",
      "V\n",
      " tensor([[[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0.]]])\n",
      "=================================\n",
      "\u001b[1m\u001b[47m\u001b[31m ITERATION : 0 \u001b[0m\n",
      "SUBSPACE SIZE V:  torch.Size([1, 8, 6])\n",
      "=================================\n",
      "V_ao.shape torch.Size([1, 6, 6])\n",
      "tensor([[[    -0.00000,     -0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.33445,     -0.00000,     -0.00000,     -0.55482,      0.53866,      0.53866],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000]]])\n",
      "** eta_anti.shape torch.Size([1, 21])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** eta_ao.shape torch.Size([1, 6, 6])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** indices[:,0] tensor([[0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]])\n",
      "** eta_anti 0.5 torch.Size([1, 1, 21])\n",
      "** eta_anti 0.5 tensor([[[     0.00000,     -0.16722,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.27741,     -0.00000,      0.00000,     -0.00000,     -0.26933,      0.00000,\n",
      "               0.00000,      0.00000,     -0.00000,     -0.26933,      0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "** eta_anti_2d torch.Size([1, 6, 6])\n",
      "** eta_anti_2d tensor([[[     0.00000,      0.16722,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.16722,      0.00000,     -0.00000,     -0.27741,      0.26933,      0.26933],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.00000,      0.27741,     -0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [    -0.00000,     -0.26933,      0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [    -0.00000,     -0.26933,      0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "*$$$ G_anti_1c2e\n",
      " tensor([[[     0.00000,     -1.67680,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     1.67680,      0.00000,      0.00000,      3.26851,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -3.26851,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "G ANTISYM shape torch.Size([1, 6, 6])\n",
      "G ANTISYM\n",
      " tensor([[[     0.00000,     -1.67680,      0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     1.67680,      0.00000,      0.00000,      3.26851,     -2.74748,     -2.74748],\n",
      "         [    -0.00000,     -0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -3.26851,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      2.74748,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      2.74748,     -0.00000,     -0.00000,     -0.00000,      0.00000]]], grad_fn=<AddBackward0>)\n",
      " %%% G ANTISYM 2C = F0\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,      0.00000,     -2.74748,     -2.74748],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      2.74748,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      2.74748,     -0.00000,     -0.00000,     -0.00000,      0.00000]]], grad_fn=<MulBackward0>)\n",
      "!!! G_full shape torch.Size([1, 6, 6])\n",
      "!!! G_full\n",
      " tensor([[[    -0.00000,     -0.19862,     -0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     3.15497,     -0.00000,      0.00000,      6.19083,     -5.49495,     -5.49495],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.34619,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,     -0.00000]]], grad_fn=<AddBackward0>)\n",
      "G_ao.shape torch.Size([1, 6, 6])\n",
      "** dgemm1.shape torch.Size([1, 6, 6])\n",
      "tensor([[[     0.00000,      0.00000,     -0.00000,      3.15497,      0.00000,      0.00000],\n",
      "         [     0.21201,     -0.00000,      0.21800,     -0.00000,      0.25850,     -0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.00000,      6.19083,     -0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,     -5.49495,     -0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,     -5.49495,     -0.00000,     -0.00000]]], grad_fn=<UnsafeViewBackward0>)\n",
      "** G_mo.shape torch.Size([8])\n",
      "tensor([    -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,     -0.00000,    -10.40985,      0.00000], grad_fn=<UnsafeViewBackward0>)\n",
      "V_ao.shape torch.Size([1, 6, 6])\n",
      "tensor([[[    -0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      0.63698,     -0.00000,     -0.54510,      0.54510],\n",
      "         [     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000]]])\n",
      "** eta_anti.shape torch.Size([1, 21])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** eta_ao.shape torch.Size([1, 6, 6])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** indices[:,0] tensor([[0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]])\n",
      "** eta_anti 0.5 torch.Size([1, 1, 21])\n",
      "** eta_anti 0.5 tensor([[[     0.00000,     -0.00000,      0.00000,     -0.00000,     -0.31849,      0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.00000,      0.27255,     -0.00000,\n",
      "              -0.00000,      0.00000,     -0.00000,     -0.27255,     -0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "** eta_anti_2d torch.Size([1, 6, 6])\n",
      "** eta_anti_2d tensor([[[     0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      0.31849,     -0.00000,     -0.27255,      0.27255],\n",
      "         [    -0.00000,     -0.31849,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,      0.27255,     -0.00000,     -0.00000,      0.00000,     -0.00000],\n",
      "         [    -0.00000,     -0.27255,     -0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "*$$$ G_anti_1c2e\n",
      " tensor([[[     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,     -3.75248,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      3.75248,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "G ANTISYM shape torch.Size([1, 6, 6])\n",
      "G ANTISYM\n",
      " tensor([[[     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,     -3.75248,      0.00000,      2.78029,     -2.78029],\n",
      "         [     0.00000,      3.75248,      0.00000,     -0.00000,     -0.00000,     -0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,     -2.78029,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      2.78029,      0.00000,     -0.00000,     -0.00000,      0.00000]]], grad_fn=<AddBackward0>)\n",
      " %%% G ANTISYM 2C = F0\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,      0.00000,      2.78029,     -2.78029],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,     -2.78029,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      2.78029,      0.00000,     -0.00000,     -0.00000,      0.00000]]], grad_fn=<MulBackward0>)\n",
      "!!! G_full shape torch.Size([1, 6, 6])\n",
      "!!! G_full\n",
      " tensor([[[     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,     -7.10751,      0.00000,      5.56058,     -5.56058],\n",
      "         [     0.00000,      0.39745,      0.00000,      0.00000,     -0.00000,      0.00000],\n",
      "         [     0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000]]], grad_fn=<AddBackward0>)\n",
      "G_ao.shape torch.Size([1, 6, 6])\n",
      "** dgemm1.shape torch.Size([1, 6, 6])\n",
      "tensor([[[    -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000],\n",
      "         [     0.00000,     -0.30639,     -0.00000,      0.00000,     -0.00000,      0.25317],\n",
      "         [    -0.00000,     -0.00000,      0.00000,     -7.10751,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      5.56058,      0.00000,     -0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -5.56058,      0.00000,      0.00000]]], grad_fn=<UnsafeViewBackward0>)\n",
      "** G_mo.shape torch.Size([8])\n",
      "tensor([     0.00000,      0.00000,     -0.00000,      0.00000,      0.00000,      0.00000,      0.00000,    -10.58943], grad_fn=<UnsafeViewBackward0>)\n",
      "V_ao.shape torch.Size([1, 6, 6])\n",
      "tensor([[[    -0.11378,     -0.00000,     -0.00000,     -0.18875,      0.18326,      0.18326],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.27589,      0.00000,      0.00000,      0.45768,     -0.44434,     -0.44434],\n",
      "         [     0.10676,      0.00000,      0.00000,      0.17711,     -0.17195,     -0.17195],\n",
      "         [     0.10676,      0.00000,      0.00000,      0.17711,     -0.17195,     -0.17195]]])\n",
      "** eta_anti.shape torch.Size([1, 21])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** eta_ao.shape torch.Size([1, 6, 6])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** indices[:,0] tensor([[0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]])\n",
      "** eta_anti 0.5 torch.Size([1, 1, 21])\n",
      "** eta_anti 0.5 tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.23232,     -0.00000,     -0.00000,      0.00000,     -0.03825,      0.00000,      0.00000,\n",
      "               0.31073,      0.00000,     -0.03825,      0.00000,      0.00000,      0.31073,      0.00000,      0.00000]]])\n",
      "** eta_anti_2d torch.Size([1, 6, 6])\n",
      "** eta_anti_2d tensor([[[     0.00000,     -0.00000,     -0.00000,     -0.23232,      0.03825,      0.03825],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.23232,     -0.00000,     -0.00000,      0.00000,     -0.31073,     -0.31073],\n",
      "         [    -0.03825,      0.00000,      0.00000,      0.31073,      0.00000,     -0.00000],\n",
      "         [    -0.03825,      0.00000,      0.00000,      0.31073,      0.00000,      0.00000]]])\n",
      "*$$$ G_anti_1c2e\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,      2.32954,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -2.32954,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "G ANTISYM shape torch.Size([1, 6, 6])\n",
      "G ANTISYM\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,      2.32954,     -0.19002,     -0.19002],\n",
      "         [    -0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,      0.08578,     -0.08578],\n",
      "         [    -2.32954,      0.00000,      0.00000,      0.00000,      3.23709,      3.23709],\n",
      "         [     0.19002,     -0.00000,     -0.08578,     -3.23709,      0.00000,      0.00000],\n",
      "         [     0.19002,     -0.00000,      0.08578,     -3.23709,     -0.00000,      0.00000]]], grad_fn=<AddBackward0>)\n",
      " %%% G ANTISYM 2C = F0\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,     -0.19002,     -0.19002],\n",
      "         [    -0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,      0.08578,     -0.08578],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      0.00000,      3.23709,      3.23709],\n",
      "         [     0.19002,     -0.00000,     -0.08578,     -3.23709,      0.00000,      0.00000],\n",
      "         [     0.19002,     -0.00000,      0.08578,     -3.23709,     -0.00000,      0.00000]]], grad_fn=<MulBackward0>)\n",
      "!!! G_full shape torch.Size([1, 6, 6])\n",
      "!!! G_full\n",
      " tensor([[[     0.32119,      0.00000,      0.00000,      1.46200,     -1.64304,     -1.64304],\n",
      "         [    -0.00000,      1.70476,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      1.36648,     -0.00000,      0.00779,     -0.00779],\n",
      "         [    -3.19708,      0.00000,     -0.00000,     -3.32494,      4.53893,      4.53893],\n",
      "         [    -1.26300,     -0.00000,     -0.16377,     -1.93525,      2.02095,      1.37258],\n",
      "         [    -1.26300,     -0.00000,      0.16377,     -1.93525,      1.37258,      2.02095]]], grad_fn=<AddBackward0>)\n",
      "G_ao.shape torch.Size([1, 6, 6])\n",
      "** dgemm1.shape torch.Size([1, 6, 6])\n",
      "tensor([[[     0.89349,      0.00000,      3.55288,     -0.00000,      0.30574,     -0.00000],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      1.70476,     -0.00000,      0.00000],\n",
      "         [     0.00000,     -0.90586,      0.00000,     -0.00000,     -0.00000,      1.04896],\n",
      "         [     0.34644,      0.00000,      4.47565,     -0.00000,     -0.72909,     -0.00000],\n",
      "         [    -0.16195,     -0.29804,     -5.38641,      0.00000,     -0.14083,     -0.34846],\n",
      "         [    -0.16195,      0.29804,     -5.38641,      0.00000,     -0.14083,      0.34846]]], grad_fn=<UnsafeViewBackward0>)\n",
      "** G_mo.shape torch.Size([8])\n",
      "tensor([    -0.66552,      0.00000,     -0.00000,     -0.25209,     -9.47437,     -0.00000,      0.00000,      0.00000], grad_fn=<UnsafeViewBackward0>)\n",
      "V_ao.shape torch.Size([1, 6, 6])\n",
      "tensor([[[    -0.00000,      0.00000,      0.21670,     -0.00000,     -0.18544,      0.18544],\n",
      "         [     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.52545,      0.00000,      0.44965,     -0.44965],\n",
      "         [     0.00000,     -0.00000,     -0.20333,      0.00000,      0.17400,     -0.17400],\n",
      "         [     0.00000,     -0.00000,     -0.20333,      0.00000,      0.17400,     -0.17400]]])\n",
      "** eta_anti.shape torch.Size([1, 21])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** eta_ao.shape torch.Size([1, 6, 6])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** indices[:,0] tensor([[0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]])\n",
      "** eta_anti 0.5 torch.Size([1, 1, 21])\n",
      "** eta_anti 0.5 tensor([[[     0.00000,     -0.00000,      0.00000,     -0.10835,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.26272,      0.00000,      0.09272,     -0.00000,     -0.10167,\n",
      "              -0.22483,      0.00000,     -0.09272,      0.00000,     -0.10167,      0.22483,      0.17400,      0.00000]]])\n",
      "** eta_anti_2d torch.Size([1, 6, 6])\n",
      "** eta_anti_2d tensor([[[     0.00000,      0.00000,      0.10835,     -0.00000,     -0.09272,      0.09272],\n",
      "         [    -0.00000,      0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [    -0.10835,      0.00000,      0.00000,      0.26272,      0.10167,      0.10167],\n",
      "         [     0.00000,     -0.00000,     -0.26272,      0.00000,      0.22483,     -0.22483],\n",
      "         [     0.09272,     -0.00000,     -0.10167,     -0.22483,      0.00000,     -0.17400],\n",
      "         [    -0.09272,      0.00000,     -0.10167,      0.22483,      0.17400,      0.00000]]])\n",
      "*$$$ G_anti_1c2e\n",
      " tensor([[[     0.00000,     -0.00000,     -1.08647,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [     1.08647,     -0.00000,      0.00000,     -3.09543,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      3.09543,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "G ANTISYM shape torch.Size([1, 6, 6])\n",
      "G ANTISYM\n",
      " tensor([[[     0.00000,     -0.00000,     -1.08647,      0.00000,      0.74049,     -0.74049],\n",
      "         [     0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000],\n",
      "         [     1.08647,     -0.00000,      0.00000,     -3.09543,     -1.09105,     -1.09105],\n",
      "         [    -0.00000,      0.00000,      3.09543,      0.00000,     -2.33582,      2.33582],\n",
      "         [    -0.74049,      0.00000,      1.09105,      2.33582,      0.00000,      1.38897],\n",
      "         [     0.74049,     -0.00000,      1.09105,     -2.33582,     -1.38897,      0.00000]]], grad_fn=<AddBackward0>)\n",
      " %%% G ANTISYM 2C = F0\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,      0.74049,     -0.74049],\n",
      "         [    -0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,     -1.09105,     -1.09105],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      0.00000,     -2.33582,      2.33582],\n",
      "         [    -0.74049,      0.00000,      1.09105,      2.33582,      0.00000,      1.38897],\n",
      "         [     0.74049,     -0.00000,      1.09105,     -2.33582,     -1.38897,      0.00000]]], grad_fn=<MulBackward0>)\n",
      "!!! G_full shape torch.Size([1, 6, 6])\n",
      "!!! G_full\n",
      " tensor([[[    -0.00000,     -0.00000,     -1.42230,      0.00000,      1.66266,     -1.66266],\n",
      "         [     0.00000,     -0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000],\n",
      "         [     0.75064,     -0.00000,      0.00000,     -0.05915,     -0.00789,     -0.00789],\n",
      "         [    -0.00000,      0.00000,      6.13172,     -0.00000,     -4.59314,      4.59314],\n",
      "         [     0.18169,      0.00000,      2.17422,      0.07850,     -0.22215,      1.38897],\n",
      "         [    -0.18169,      0.00000,      2.17422,     -0.07850,     -1.38897,      0.22215]]], grad_fn=<AddBackward0>)\n",
      "G_ao.shape torch.Size([1, 6, 6])\n",
      "** dgemm1.shape torch.Size([1, 6, 6])\n",
      "tensor([[[     0.00000,     -0.74232,     -0.00000,     -0.00000,      0.00000,      0.28006],\n",
      "         [    -0.00000,      0.00000,     -0.00000,     -0.00000,     -0.00000,     -0.00000],\n",
      "         [    -0.84200,      0.00000,     -6.93003,      0.00000,     -0.58401,     -0.00000],\n",
      "         [    -0.00000,     -0.02512,      0.00000,     -0.00000,      0.00000,     -0.12326],\n",
      "         [    -0.43504,     -0.51947,      4.86883,     -0.00000,      1.12446,     -0.64105],\n",
      "         [     0.43504,     -0.51947,     -4.86883,      0.00000,     -1.12446,     -0.64105]]], grad_fn=<UnsafeViewBackward0>)\n",
      "** G_mo.shape torch.Size([8])\n",
      "tensor([     0.00000,     -0.06206,     -0.29743,     -0.00000,     -0.00000,     -9.72224,     -0.00000,      0.00000], grad_fn=<UnsafeViewBackward0>)\n",
      "V_ao.shape torch.Size([1, 6, 6])\n",
      "tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.25782,      0.00000,      0.00000,      0.42770,     -0.41525,     -0.41525],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [     0.15064,      0.00000,      0.00000,      0.24990,     -0.24262,     -0.24262],\n",
      "         [    -0.15064,     -0.00000,     -0.00000,     -0.24990,      0.24262,      0.24262]]])\n",
      "** eta_anti.shape torch.Size([1, 21])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** eta_ao.shape torch.Size([1, 6, 6])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** indices[:,0] tensor([[0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]])\n",
      "** eta_anti 0.5 torch.Size([1, 1, 21])\n",
      "** eta_anti 0.5 tensor([[[     0.00000,      0.00000,      0.00000,      0.12891,      0.00000,      0.00000,     -0.00000,     -0.00000,     -0.21385,      0.00000,      0.07532,      0.00000,      0.20762,\n",
      "               0.12495,      0.00000,     -0.07532,      0.00000,      0.20762,     -0.12495,      0.24262,      0.00000]]])\n",
      "** eta_anti_2d torch.Size([1, 6, 6])\n",
      "** eta_anti_2d tensor([[[     0.00000,     -0.00000,     -0.12891,      0.00000,     -0.07532,      0.07532],\n",
      "         [     0.00000,      0.00000,     -0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.12891,      0.00000,      0.00000,      0.21385,     -0.20762,     -0.20762],\n",
      "         [    -0.00000,     -0.00000,     -0.21385,      0.00000,     -0.12495,      0.12495],\n",
      "         [     0.07532,      0.00000,      0.20762,      0.12495,      0.00000,     -0.24262],\n",
      "         [    -0.07532,      0.00000,      0.20762,     -0.12495,      0.24262,      0.00000]]])\n",
      "*$$$ G_anti_1c2e\n",
      " tensor([[[     0.00000,      0.00000,      1.29261,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -1.29261,     -0.00000,      0.00000,     -2.51964,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      2.51964,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "G ANTISYM shape torch.Size([1, 6, 6])\n",
      "G ANTISYM\n",
      " tensor([[[     0.00000,      0.00000,      1.29261,     -0.00000,      1.07657,     -1.07657],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -1.29261,     -0.00000,      0.00000,     -2.51964,      2.33564,      2.33564],\n",
      "         [     0.00000,      0.00000,      2.51964,      0.00000,      1.44548,     -1.44548],\n",
      "         [    -1.07657,     -0.00000,     -2.33564,     -1.44548,      0.00000,      1.93671],\n",
      "         [     1.07657,     -0.00000,     -2.33564,      1.44548,     -1.93671,      0.00000]]], grad_fn=<AddBackward0>)\n",
      " %%% G ANTISYM 2C = F0\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,      1.07657,     -1.07657],\n",
      "         [    -0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,      2.33564,      2.33564],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      0.00000,      1.44548,     -1.44548],\n",
      "         [    -1.07657,     -0.00000,     -2.33564,     -1.44548,      0.00000,      1.93671],\n",
      "         [     1.07657,     -0.00000,     -2.33564,      1.44548,     -1.93671,      0.00000]]], grad_fn=<MulBackward0>)\n",
      "!!! G_full shape torch.Size([1, 6, 6])\n",
      "!!! G_full\n",
      " tensor([[[     0.00000,      0.00000,     -0.71409,     -0.00000,      0.37106,     -0.37106],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -3.29931,     -0.00000,     -0.00000,     -5.14707,      4.44019,      4.44019],\n",
      "         [     0.00000,      0.00000,     -0.10780,      0.00000,      0.16031,     -0.16031],\n",
      "         [    -1.78209,     -0.00000,     -0.23109,     -2.73064,      1.07507,      1.93671],\n",
      "         [     1.78209,      0.00000,     -0.23109,      2.73064,     -1.93671,     -1.07507]]], grad_fn=<AddBackward0>)\n",
      "G_ao.shape torch.Size([1, 6, 6])\n",
      "** dgemm1.shape torch.Size([1, 6, 6])\n",
      "tensor([[[    -0.00000,      4.14873,      0.00000,     -0.00000,     -0.00000,     -0.15877],\n",
      "         [    -0.00000,      0.00000,     -0.00000,      0.00000,     -0.00000,     -0.00000],\n",
      "         [     0.79110,      0.00000,     -0.00648,     -0.00000,      0.04968,      0.00000],\n",
      "         [     0.00000,      6.42761,      0.00000,     -0.00000,      0.00000,     -0.30165],\n",
      "         [    -0.06036,     -4.77940,      0.26904,      0.00000,     -0.67718,      1.18660],\n",
      "         [     0.06036,     -4.77940,     -0.26904,      0.00000,      0.67718,      1.18660]]], grad_fn=<UnsafeViewBackward0>)\n",
      "** G_mo.shape torch.Size([8])\n",
      "tensor([    -0.00000,      0.56971,    -10.10270,      0.00000,     -0.00000,     -0.29743,      0.00000,     -0.00000], grad_fn=<UnsafeViewBackward0>)\n",
      "V_ao.shape torch.Size([1, 6, 6])\n",
      "tensor([[[     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.49103,      0.00000,      0.42020,     -0.42020],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.28690,      0.00000,      0.24552,     -0.24552],\n",
      "         [    -0.00000,      0.00000,      0.28690,     -0.00000,     -0.24552,      0.24552]]])\n",
      "** eta_anti.shape torch.Size([1, 21])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** eta_ao.shape torch.Size([1, 6, 6])\n",
      "** indices torch.Size([1, 2, 21])\n",
      "** indices[:,0] tensor([[0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]])\n",
      "** eta_anti 0.5 torch.Size([1, 1, 21])\n",
      "** eta_anti 0.5 tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000,     -0.35355,\n",
      "               0.00000,      0.00000,      0.00000,      0.00000,      0.35355,     -0.00000,     -0.00000,      0.00000]]])\n",
      "** eta_anti_2d torch.Size([1, 6, 6])\n",
      "** eta_anti_2d tensor([[[     0.00000,     -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,     -0.00000,      0.35355,     -0.35355],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,     -0.35355,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.35355,     -0.00000,     -0.00000,      0.00000]]])\n",
      "*$$$ G_anti_1c2e\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,      0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,     -0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,      0.00000,      0.00000,      0.00000]]])\n",
      "G ANTISYM shape torch.Size([1, 6, 6])\n",
      "G ANTISYM\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,     -0.00000,     -0.31593,     -0.31593],\n",
      "         [    -0.00000,      0.00000,      0.00000,     -0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,     -3.78053,      3.78053],\n",
      "         [     0.00000,      0.00000,     -0.00000,      0.00000,     -0.13650,     -0.13650],\n",
      "         [     0.31593,      0.00000,      3.78053,      0.13650,      0.00000,     -0.00000],\n",
      "         [     0.31593,     -0.00000,     -3.78053,      0.13650,      0.00000,      0.00000]]], grad_fn=<AddBackward0>)\n",
      " %%% G ANTISYM 2C = F0\n",
      " tensor([[[     0.00000,      0.00000,      0.00000,      0.00000,     -0.31593,     -0.31593],\n",
      "         [    -0.00000,      0.00000,      0.00000,      0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,     -0.00000,      0.00000,      0.00000,     -3.78053,      3.78053],\n",
      "         [    -0.00000,     -0.00000,     -0.00000,      0.00000,     -0.13650,     -0.13650],\n",
      "         [     0.31593,      0.00000,      3.78053,      0.13650,      0.00000,     -0.00000],\n",
      "         [     0.31593,     -0.00000,     -3.78053,      0.13650,      0.00000,      0.00000]]], grad_fn=<MulBackward0>)\n",
      "!!! G_full shape torch.Size([1, 6, 6])\n",
      "!!! G_full\n",
      " tensor([[[     0.33626,      0.00000,      0.00000,      0.68884,     -0.37549,     -0.37549],\n",
      "         [    -0.00000,     -1.85907,      0.00000,     -0.00000,     -0.00000,      0.00000],\n",
      "         [    -0.00000,      0.00000,      3.79661,     -0.00000,     -4.49323,      4.49323],\n",
      "         [     0.68884,     -0.00000,     -0.00000,     -1.56146,     -0.16223,     -0.16223],\n",
      "         [     0.25637,      0.00000,      3.06782,      0.11076,     -2.94929,      1.95984],\n",
      "         [     0.25637,     -0.00000,     -3.06782,      0.11076,      1.95984,     -2.94929]]], grad_fn=<AddBackward0>)\n",
      "G_ao.shape torch.Size([1, 6, 6])\n",
      "** dgemm1.shape torch.Size([1, 6, 6])\n",
      "tensor([[[    -0.53851,      0.00000,     -0.61750,     -0.00000,     -0.21845,     -0.00000],\n",
      "         [     0.00000,      0.00000,      0.00000,     -1.85907,      0.00000,     -0.00000],\n",
      "         [     0.00000,     -5.69031,      0.00000,      0.00000,      0.00000,     -0.92616],\n",
      "         [    -0.50926,      0.00000,      1.45168,      0.00000,      0.75528,      0.00000],\n",
      "         [     0.67264,      5.67488,      0.32193,     -0.00000,     -0.31739,     -0.18613],\n",
      "         [     0.67264,     -5.67488,      0.32193,      0.00000,     -0.31739,      0.18613]]], grad_fn=<UnsafeViewBackward0>)\n",
      "** G_mo.shape torch.Size([8])\n",
      "tensor([     1.18730,     -0.00000,      0.00000,     -9.81131,     -0.25209,     -0.00000,     -0.00000,      0.00000], grad_fn=<UnsafeViewBackward0>)\n",
      "L_xi.shape torch.Size([1, 8, 6])\n",
      "L_xi\n",
      " tensor([[[    -0.00000,      0.00000,     -0.66552,      0.00000,     -0.00000,      1.18730],\n",
      "         [     0.00000,      0.00000,      0.00000,     -0.06206,      0.56971,     -0.00000],\n",
      "         [     0.00000,     -0.00000,     -0.00000,     -0.29743,    -10.10270,      0.00000],\n",
      "         [    -0.00000,      0.00000,     -0.25209,     -0.00000,      0.00000,     -9.81131],\n",
      "         [     0.00000,      0.00000,     -9.47437,     -0.00000,     -0.00000,     -0.25209],\n",
      "         [    -0.00000,      0.00000,     -0.00000,     -9.72224,     -0.29743,     -0.00000],\n",
      "         [   -10.40985,      0.00000,      0.00000,     -0.00000,      0.00000,     -0.00000],\n",
      "         [     0.00000,    -10.58943,      0.00000,      0.00000,     -0.00000,      0.00000]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "STOP",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mseqm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseqm_functions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcited\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39morb_transform\u001b[39;00m \u001b[39mimport\u001b[39;00m mo2ao\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m mol \u001b[39m=\u001b[39m run_seqm_1mol(\u001b[39m'\u001b[39m\u001b[39mh2o.xyz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39meval\u001b[39m, _ \u001b[39m=\u001b[39m davidson(device \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                    mol \u001b[39m=\u001b[39;49m mol, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                    N_exc \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                    keep_n \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                    n_V_max \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                    max_iter \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                    tol \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1e-6\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m logger\u001b[39m.\u001b[39mdebug(fmt_log(\u001b[39meval\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFINAL eval \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mevals\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mL_xi.shape\u001b[39m\u001b[39m'\u001b[39m, L_xi\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mL_xi\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, L_xi)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSTOP\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m L_xi[N_cis:, :] \u001b[39m=\u001b[39m L_xi[:N_cis] \u001b[39m#! TODO: make sure that this A+B, A-B, not just copy for RPA\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22574f524b53544154494f4e227d/nh/nest/u/fns/github/PYSEQM/examples/davidson_optimization.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m right_V \u001b[39m=\u001b[39m L_xi[N_cis:] \u001b[39m# (A)b \u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: STOP"
     ]
    }
   ],
   "source": [
    "# mol = run_seqm_1mol('c6h6.xyz')\n",
    "# eval, _ = davidson(mol = mol, \n",
    "#                    N_exc = 8,\n",
    "#                    keep_n = 4,\n",
    "#                    n_V_max = 50, \n",
    "#                    max_iter = 50, \n",
    "#                    tol = 1e-6)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "logger.debug(fmt_log(eval, 'FINAL eval ', 'evals'))\n",
    "from seqm.seqm_functions.excited import ortho as orthogonalize\n",
    "from seqm.seqm_functions.excited.hamiltonian import gen_V\n",
    "from seqm.seqm_functions.excited.hamiltonian import form_cis\n",
    "from seqm.seqm_functions.excited.orb_transform import mo2ao\n",
    "\n",
    "\n",
    "\n",
    "mol = run_seqm_1mol('h2o.xyz')\n",
    "eval, _ = davidson(device = 'cpu', \n",
    "                   mol = mol, \n",
    "                   N_exc = 3,\n",
    "                   keep_n = 2,\n",
    "                   n_V_max = 10, \n",
    "                   max_iter = 3, \n",
    "                   tol = -1e-6)\n",
    "\n",
    "logger.debug(fmt_log(eval, 'FINAL eval ', 'evals'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "del eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    -0.87887,     -0.00000,      0.34020,      0.00000,     -0.33445,     -0.00000],\n",
       "         [    -0.00000,     -0.00000,     -0.00000,      1.00000,     -0.00000,      0.00000],\n",
       "         [    -0.00000,     -0.77088,     -0.00000,     -0.00000,     -0.00000,      0.63698],\n",
       "         [    -0.10818,      0.00000,     -0.82490,     -0.00000,     -0.55482,     -0.00000],\n",
       "         [    -0.32855,     -0.45041,     -0.31921,     -0.00000,      0.53866,     -0.54510],\n",
       "         [    -0.32855,      0.45041,     -0.31921,     -0.00000,      0.53866,      0.54510]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol.C_mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    -0.87887,     -0.00000,     -0.00000,     -0.10818,     -0.32855,     -0.32855],\n",
       "         [    -0.00000,     -0.00000,     -0.77088,      0.00000,     -0.45041,      0.45041],\n",
       "         [     0.34020,     -0.00000,     -0.00000,     -0.82490,     -0.31921,     -0.31921],\n",
       "         [     0.00000,      1.00000,     -0.00000,     -0.00000,     -0.00000,     -0.00000],\n",
       "         [    -0.33445,     -0.00000,     -0.00000,     -0.55482,      0.53866,      0.53866],\n",
       "         [    -0.00000,      0.00000,      0.63698,     -0.00000,     -0.54510,      0.54510]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol.C_mo.transpose(1,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
